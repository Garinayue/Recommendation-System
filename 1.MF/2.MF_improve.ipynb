{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内容说明\n",
    "背景：之前自己手动实现 MF 算法的整个过程，便于掌握 MF 算法的基本原理，但是运行速度非常缓慢  \n",
    "目的：希望在掌握原理之后借用Pytorch中的已有库，同时采取改进措施优化时间性能  \n",
    "改进方向：  \n",
    "1. 分batch，同一个batch可以并行计算，极大改善时间性能\n",
    "2. 调用Pytorch中自带的优化器  \n",
    "3. 减少对df文件以及评分矩阵的遍历，尽可能改善时间性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 编写MF类\n",
    "1. init(): 初始化各个参数，包括：  \n",
    "1) 学习率lr  \n",
    "2) L2系数weight_decay（注意：不用自己计算正则化范数，直接利用优化器的weight_decay参数即可）  \n",
    "3) 嵌入维数embed_size  \n",
    "4) 批大小batch_size  \n",
    "5) 训练文件df_train，测试文件df_test  \n",
    "6) 训练评分矩阵R_train，测试评分矩阵R_test  \n",
    "7) 参数矩阵P和Q，偏置mu, bu和bi。  \n",
    "2. preprocess(df, ratio_train): 参数为文件df以及训练集所占比例ratio_train。首先，划分训练与测试数据；其次，根据df文件，获取n_P和n_Q值，便于根据这个维度初始化各个变量与矩阵；计算mu值。  \n",
    "3. generate_train(): 生成批训练集，得到每一批数据中user和item对应的编号矩阵，同时可以填充R_train矩阵  \n",
    "4. train(): 多次迭代训练，优化参数  \n",
    "5. performance(): 计算RMSE和MAE的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MF():\n",
    "    \n",
    "    # 初始化参数\n",
    "    def __init__(self, lr=0.005, weight_decay=0.05, embed_size=10, batch_size=2000):\n",
    "        \n",
    "        # 常用参数\n",
    "        self.lr = lr  # 优化器参数\n",
    "        self.weight_decay = weight_decay  # 优化器参数\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # 训练测试的df文件与评分矩阵\n",
    "        self.df_train = None\n",
    "        self.df_test = None\n",
    "        self.R_train = None\n",
    "        self.R_test = None\n",
    "\n",
    "        # user和item的参数矩阵\n",
    "        self.P = None\n",
    "        self.Q = None\n",
    "        \n",
    "        # 三种偏置\n",
    "        self.mu = 0\n",
    "        self.bu = None\n",
    "        self.bi = None\n",
    "    \n",
    "    \n",
    "    # 读取文件，划分训练测试集，完善初始化参数\n",
    "    def preprocess(self, df, ratio_train):\n",
    "        # 划分数据\n",
    "        n_train = int(ratio_train * df.shape[0])\n",
    "        self.df_train = df[:n_train]\n",
    "        self.df_test = df[n_train:df.shape[0]]\n",
    "        \n",
    "        # 获取n_P, n_Q值，计算mu值\n",
    "        n_P = df['user_id:token'].max() + 1\n",
    "        n_Q = df['item_id:token'].max() + 1\n",
    "        self.mu = self.df_train['rating:float'].sum(axis=0) / self.df_train.shape[0]\n",
    "        print('n_P = %d, n_Q = %d, mu = %.4f' % (n_P, n_Q, self.mu))\n",
    "        \n",
    "        # 补充初始化\n",
    "        self.R_train = torch.zeros(n_P, n_Q)\n",
    "        self.R_test = torch.zeros(n_P, n_Q)\n",
    "        self.P = nn.Parameter(torch.empty(n_P, self.embed_size))\n",
    "        self.Q = nn.Parameter(torch.empty(n_Q, self.embed_size))\n",
    "        self.bu = nn.Parameter(torch.empty(n_P, 1))\n",
    "        self.bi = nn.Parameter(torch.empty(n_Q, 1))\n",
    "        nn.init.xavier_normal_(self.P.data)\n",
    "        nn.init.xavier_normal_(self.Q.data)\n",
    "        nn.init.xavier_normal_(self.bu.data)\n",
    "        nn.init.xavier_normal_(self.bi.data)\n",
    "        \n",
    "    \n",
    "    # 生成批训练集的 u, i索引，同时填充评分矩阵R_train\n",
    "    def generate_train_batch(self):\n",
    "        n_train = self.df_train.shape[0]\n",
    "        n_batch = n_train // self.batch_size\n",
    "        \n",
    "        # 针对每个batch，分别生成user和item索引\n",
    "        for k in range(n_batch):\n",
    "            u_batch = []\n",
    "            i_batch = []\n",
    "            df_batch = self.df_train[k*self.batch_size: (k+1)*self.batch_size]\n",
    "            for index, row in df_batch.iterrows():\n",
    "                u = row['user_id:token']\n",
    "                i = row['item_id:token']\n",
    "                rui = row['rating:float']\n",
    "                u_batch.append(u)\n",
    "                i_batch.append(i)\n",
    "                self.R_train[u][i] = rui  # 填充评分矩阵\n",
    "            yield np.asarray(u_batch), np.asarray(i_batch)\n",
    "    \n",
    "    \n",
    "    # 迭代训练，优化参数\n",
    "    def train(self, epochs):\n",
    "        # 定义优化器\n",
    "        optimizer = optim.Adam([self.P, self.Q, self.bu, self.bi], lr=self.lr, weight_decay=self.weight_decay)\n",
    "        print(\"\\nstart training......\")\n",
    "        \n",
    "        # 多次迭代\n",
    "        for k in range(epochs):\n",
    "            sum_loss = 0\n",
    "            # 针对每个小batch\n",
    "            for u_batch, i_batch in self.generate_train_batch():\n",
    "                pu = self.P[u_batch, :]\n",
    "                qi = self.Q[i_batch, :]\n",
    "                rui = self.R_train[u_batch, i_batch]  # 真实评分\n",
    "                rui_pred = torch.mul(pu, qi).sum(dim=1) + self.bu[u_batch].sum(dim=1) + self.bi[i_batch].sum(dim=1) + self.mu\n",
    "                # 计算误差\n",
    "                square = (rui-rui_pred).pow(2).sum()\n",
    "                #L2 = self.lmbda * (pu.norm(dim=1).pow(2).sum() + qi.norm(dim=1).pow(2).sum() + self.bu.norm(dim=0).pow(2) + self.bi.norm(dim=0).pow(2))\n",
    "                loss = square\n",
    "                sum_loss += loss\n",
    "                # 优化参数\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # 输出均差，评估性能\n",
    "            avg_loss = sum_loss/self.df_train.shape[0]\n",
    "            rmse, mae = self.test_RMSE()\n",
    "            ndcg = self.test_NDCG(10)\n",
    "            print('epoch %d：avg_loss = %.4f;   RMSE = %.4f, MAE = %.4f, NDCG = %.4f' % (k+1, avg_loss, rmse, mae, ndcg))\n",
    "    \n",
    "    \n",
    "    # 评估性能RMSE，MAE\n",
    "    def test_RMSE(self):\n",
    "        u_test = []\n",
    "        i_test = []\n",
    "        \n",
    "        # 遍历测试数据，记录user和item索引以及评分\n",
    "        for index, row in self.df_test.iterrows():\n",
    "            u = row['user_id:token']\n",
    "            i = row['item_id:token']\n",
    "            rui = row['rating:float']\n",
    "            u_test.append(u)\n",
    "            i_test.append(i)\n",
    "            self.R_test[u][i] = rui\n",
    "        \n",
    "        # 提取user和item向量\n",
    "        u_test = np.asarray(u_test)\n",
    "        i_test = np.asarray(i_test)\n",
    "        pu = self.P[u_test, :]\n",
    "        qi = self.Q[i_test, :]\n",
    "        \n",
    "        # 获取真实评分并计算预测评分（不是U*I矩阵形式，而是一行数值，没有0值）\n",
    "        rui = self.R_test[u_test, i_test]  # 真实评分\n",
    "        rui_pred = torch.mul(pu, qi).sum(dim=1) + self.bu[u_test].sum(dim=1) + self.bi[i_test].sum(dim=1) + self.mu\n",
    "        \n",
    "        # 计算RMSE与MAE\n",
    "        r = rui.data.numpy()\n",
    "        r_pred = rui_pred.data.numpy()\n",
    "        rmse = np.sqrt(mean_squared_error(r, r_pred))\n",
    "        mae = mean_absolute_error(r, r_pred)\n",
    "        \n",
    "        # 返回\n",
    "        return rmse, mae\n",
    "    \n",
    "    \n",
    "    # 评估性能NDCG\n",
    "    def test_NDCG(self, K):\n",
    "        n_P = self.R_test.shape[0]\n",
    "        n_Q = self.R_test.shape[1]\n",
    "        R_pred = torch.matmul(self.P, self.Q.t()) + self.mu + self.bu + self.bi.t()  # 预测矩阵\n",
    "        R_pred -= 100*self.R_train  # 去除用于训练集的评分数据，减去100则排序后处于最后，不影响排序与计算\n",
    "        '''\n",
    "        # 遍历测试数据，记录实际评分，计算预测评分\n",
    "        for index, row in self.df_test.iterrows():\n",
    "            u = row['user_id:token']\n",
    "            i = row['item_id:token']\n",
    "            rui = row['rating:float']\n",
    "            pu = self.P[u]\n",
    "            qi = self.Q[i]\n",
    "            self.R_test[u][i] = rui  # 实际评分\n",
    "            R_pred[u][i] = sum(pu*qi) + self.bu[u] + self.bi[i] + self.mu  # 预测评分。没有生成整个预测的矩阵再提取测试部分，否则遍历矩阵浪费时间\n",
    "        '''\n",
    "        # 排序\n",
    "        sort_results1, indices1 = torch.sort(self.R_test, descending=True)\n",
    "        sort_results2, indices2 = torch.sort(R_pred, descending=True)\n",
    "        \n",
    "        # 计算DCG，使用真实评分与预测的排序\n",
    "        # 计算IDCG，使用真实评分与真实排序\n",
    "        \n",
    "        ndcg = 0\n",
    "        n = n_P - 1\n",
    "        for u in range(1, n_P):\n",
    "            dcg = 0\n",
    "            idcg = 0\n",
    "            for idx in range(K):\n",
    "                a = torch.tensor([idx+2])\n",
    "                i = indices2[u][idx]\n",
    "                dcg += (2**self.R_test[u][i]-1)/(torch.log2(a))\n",
    "                idcg += (2**sort_results1[u][idx]-1)/(torch.log2(a))\n",
    "            # 有的用户在测试数据中没评过分，idcg=0不可以做分母\n",
    "            if idcg == 0:\n",
    "                n -= 1\n",
    "            else:\n",
    "                ndcg += dcg / idcg  # 各用户的ndcg求和\n",
    "        ndcg /= n  # 计算每个用户的平均ndcg\n",
    "        \n",
    "        return ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些实现心得\n",
    "改进时间性能非常重要，否则可能相差几十上百倍的时间  \n",
    "1. 划分batch：划分成一定大小的batch后，如果仍依次遍历一个batch中的样本，对时间没有任何改进。而应该利用矩阵或者向量的方式，同时对一个batch中的所有样本进行计算。  \n",
    "2. 尽量减少对df文件的遍历：实验中df文件有十万行，以计算评分均值mu为例，入股遍历df每一行求评分和，将会十分缓慢。相反，可以直接用df['rating:float'].sum()相当快速求和。\n",
    "3. 尽量减少对评分矩阵的遍历：实验中评分矩阵维度为(944, 1683)，需要遍历158万个数据，非常缓慢。以计算RMSE指标为例，不能直接对944×1683的R_test矩阵调用mean_squared_error()，因为矩阵中只有20000个是测试数据，其它很多0是未评分的。如果遍历矩阵，判断rui是否为0，再累加计算RMSE，非常缓慢。为了改进时间复杂度，可以根据df_test文件获取测试数据的user和item编号矩阵，借鉴batch中的并行方式，构建只包含测试数据的评分矩阵，再直接调用mean_squared_error()。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 运行与测试\n",
    "分别使用显式评分文件和隐式评分文件来运行测试  \n",
    "显式数据集：就是原始ml-100k数据集中的.inter文件得到的，已评分的分值在1-5之间，还有未评分的0  \n",
    "隐式数据集1：为了跟BPR对比性能，将4分和5分记为1，1-3分以及未评分的记为0  \n",
    "隐式数据集2：将已评分的都记为1，未评分的都记为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_P = 944, n_Q = 1683, mu = 3.5295\n",
      "\n",
      "start training......\n",
      "epoch 1：avg_loss = 1.1723;   RMSE = 1.0329, MAE = 0.8481, NDCG = 0.1169\n",
      "epoch 2：avg_loss = 1.0002;   RMSE = 0.9626, MAE = 0.7682, NDCG = 0.1351\n",
      "epoch 3：avg_loss = 0.8852;   RMSE = 0.9314, MAE = 0.7396, NDCG = 0.1288\n",
      "epoch 4：avg_loss = 0.8286;   RMSE = 0.9179, MAE = 0.7278, NDCG = 0.1257\n",
      "epoch 5：avg_loss = 0.7960;   RMSE = 0.9110, MAE = 0.7216, NDCG = 0.1240\n",
      "epoch 6：avg_loss = 0.7730;   RMSE = 0.9069, MAE = 0.7178, NDCG = 0.1225\n",
      "epoch 7：avg_loss = 0.7540;   RMSE = 0.9042, MAE = 0.7151, NDCG = 0.1217\n",
      "epoch 8：avg_loss = 0.7368;   RMSE = 0.9022, MAE = 0.7131, NDCG = 0.1223\n",
      "epoch 9：avg_loss = 0.7206;   RMSE = 0.9009, MAE = 0.7117, NDCG = 0.1239\n",
      "epoch 10：avg_loss = 0.7054;   RMSE = 0.9001, MAE = 0.7109, NDCG = 0.1252\n",
      "epoch 11：avg_loss = 0.6917;   RMSE = 0.8998, MAE = 0.7104, NDCG = 0.1255\n",
      "epoch 12：avg_loss = 0.6794;   RMSE = 0.8998, MAE = 0.7103, NDCG = 0.1250\n",
      "epoch 13：avg_loss = 0.6687;   RMSE = 0.9001, MAE = 0.7103, NDCG = 0.1260\n",
      "epoch 14：avg_loss = 0.6595;   RMSE = 0.9005, MAE = 0.7104, NDCG = 0.1259\n",
      "epoch 15：avg_loss = 0.6516;   RMSE = 0.9010, MAE = 0.7106, NDCG = 0.1258\n"
     ]
    }
   ],
   "source": [
    "# 显式数据集\n",
    "\n",
    "# 读取文件并随机打乱\n",
    "inter = pd.read_csv('../dataset/ml-100k/inter_explicit.csv')\n",
    "df = pd.DataFrame(inter)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 建立MF模型并训练测试\n",
    "mf = MF(lr=0.003, weight_decay=0.1, embed_size=10, batch_size=500)\n",
    "mf.preprocess(df, ratio_train=0.8)\n",
    "mf.train(epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_P = 944, n_Q = 1683, mu = 0.5538\n",
      "\n",
      "start training......\n",
      "epoch 1：avg_loss = 0.2206;   RMSE = 0.4510, MAE = 0.4280, NDCG = 0.1102\n",
      "epoch 2：avg_loss = 0.1953;   RMSE = 0.4412, MAE = 0.4035, NDCG = 0.0913\n",
      "epoch 3：avg_loss = 0.1882;   RMSE = 0.4372, MAE = 0.3934, NDCG = 0.0858\n",
      "epoch 4：avg_loss = 0.1846;   RMSE = 0.4354, MAE = 0.3889, NDCG = 0.0851\n",
      "epoch 5：avg_loss = 0.1827;   RMSE = 0.4346, MAE = 0.3867, NDCG = 0.0867\n",
      "epoch 6：avg_loss = 0.1817;   RMSE = 0.4341, MAE = 0.3856, NDCG = 0.0872\n",
      "epoch 7：avg_loss = 0.1810;   RMSE = 0.4338, MAE = 0.3848, NDCG = 0.0877\n",
      "epoch 8：avg_loss = 0.1805;   RMSE = 0.4336, MAE = 0.3844, NDCG = 0.0879\n",
      "epoch 9：avg_loss = 0.1801;   RMSE = 0.4334, MAE = 0.3840, NDCG = 0.0889\n",
      "epoch 10：avg_loss = 0.1798;   RMSE = 0.4333, MAE = 0.3837, NDCG = 0.0891\n",
      "epoch 11：avg_loss = 0.1794;   RMSE = 0.4331, MAE = 0.3835, NDCG = 0.0904\n",
      "epoch 12：avg_loss = 0.1791;   RMSE = 0.4330, MAE = 0.3833, NDCG = 0.0910\n",
      "epoch 13：avg_loss = 0.1789;   RMSE = 0.4329, MAE = 0.3832, NDCG = 0.0913\n",
      "epoch 14：avg_loss = 0.1786;   RMSE = 0.4328, MAE = 0.3830, NDCG = 0.0919\n",
      "epoch 15：avg_loss = 0.1783;   RMSE = 0.4327, MAE = 0.3829, NDCG = 0.0927\n"
     ]
    }
   ],
   "source": [
    "# 隐式数据集1\n",
    "\n",
    "# 读取文件并随机打乱\n",
    "inter = pd.read_csv('../dataset/ml-100k/inter_implicit1.csv')\n",
    "df = pd.DataFrame(inter)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 建立MF模型并训练测试\n",
    "mf = MF(lr=0.003, weight_decay=0.1, embed_size=10, batch_size=500)\n",
    "mf.preprocess(df, ratio_train=0.8)\n",
    "mf.train(epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_P = 944, n_Q = 1683, mu = 1.0000\n",
      "\n",
      "start training......\n",
      "epoch 1：avg_loss = 0.0008;   RMSE = 0.0082, MAE = 0.0041, NDCG = 0.0058\n",
      "epoch 2：avg_loss = 0.0000;   RMSE = 0.0017, MAE = 0.0005, NDCG = 0.0049\n",
      "epoch 3：avg_loss = 0.0000;   RMSE = 0.0004, MAE = 0.0001, NDCG = 0.0044\n",
      "epoch 4：avg_loss = 0.0000;   RMSE = 0.0001, MAE = 0.0000, NDCG = 0.0034\n",
      "epoch 5：avg_loss = 0.0000;   RMSE = 0.0000, MAE = 0.0000, NDCG = 0.0025\n"
     ]
    }
   ],
   "source": [
    "# 隐式数据集2\n",
    "\n",
    "# 读取文件并随机打乱\n",
    "inter = pd.read_csv('../dataset/ml-100k/inter_implicit2.csv')\n",
    "df = pd.DataFrame(inter)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 建立MF模型并训练测试\n",
    "mf = MF(lr=0.001, weight_decay=0.1, embed_size=10, batch_size=500)\n",
    "mf.preprocess(df, ratio_train=0.8)\n",
    "mf.train(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
