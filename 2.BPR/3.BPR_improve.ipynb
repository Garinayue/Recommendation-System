{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 内容说明\n",
    "背景：之前自己手动实现 BPR 算法的整个过程，便于掌握算法的基本原理，但无法在整个数据集上使用，时间性能难以接受  \n",
    "目的：希望在掌握原理之后借用Pytorch中的库，同时采取改进措施优化时间性能  \n",
    "改进方向：  \n",
    "1. 引入采样，因为遍历所有的[u, i, j]三元组复杂度为n_user\\*n_item\\*item，太过庞大\n",
    "2. 分batch，同一个batch可以并行计算，极大改善时间性能\n",
    "3. 调用Pytorch中自带的优化器  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写BPR类\n",
    "1. init(): 初始化各个参数  \n",
    "1) n_P：user数目加1，因为从1开始编号  \n",
    "2) n_Q：item数目加1  \n",
    "3) rated_dict：记录每个user已经评分的item编号集合  \n",
    "4) lr：学习率  \n",
    "5) lmbda：L2系数  \n",
    "6) embed_size：嵌入维数  \n",
    "7) batch_size：批大小  \n",
    "8) P：user的参数矩阵   \n",
    "9) Q：item的参数矩阵  \n",
    "10) one_rated：字典，针对每个user，从已评分的item中随机选择一个，用于构造测试集。  \n",
    "  \n",
    "2. generate_train_batch()：生成批训练集，每一批样本数为batch_size  \n",
    "1) 随机选择一个user编号，记录在u_batch中；  \n",
    "2) 在该user已评分的item中，随机选择一个item编号，记录在i_batch中（注意不能选到one_rated中用于构造测试集的）；  \n",
    "3) 在该user未评分的item中，随机选择一个item编号，记录在j_batch中；  \n",
    "4) 返回编号列表u_batch, i_batch, j_batch，便于一批的并行计算；  \n",
    "\n",
    "3. generate_test_batch()：生成批训练集，每一批对应一个user  \n",
    "1) 针对编号为u的user  \n",
    "2) one_rated中选择了编号为i的已评分item   \n",
    "3) 遍历该用户未评分的item，记录编号到j_test中  \n",
    "4) 返回编号列表u_test, i_test, j_test，便于一批的并行计算(每个u_test中的元素都是一样的，因为一个user为一批；每个i_test中的元素也是一样的，因为一个用户只选了一个已评分item记录在one_rated中)\n",
    "\n",
    "4. compute_loss()：计算损失值之和。参数为u,i,j编号矩阵，三个矩阵维数相同。不用遍历样本，而是借助矩阵运算加速  \n",
    "5. train(epochs)：训练，优化参数  \n",
    "6. test()：在测试集上计算平均误差，看是否下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    \n",
    "    def __init__(self, n_P, n_Q, rated_dict, lr=0.005, lmbda=0.05, embed_size=10, batch_size=1000):\n",
    "        \n",
    "        # 常用参数\n",
    "        self.n_P = n_P\n",
    "        self.n_Q = n_Q\n",
    "        self.lr = lr\n",
    "        self.lmbda = lmbda\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # 评分相关的字典\n",
    "        self.rated_dict = rated_dict  # 记录每个user已评分的item编号\n",
    "        self.one_rated = dict()  # 从每个user已评分的item中随机选出来一个，用于训练集和测试集的构造\n",
    "        for u, i_set in self.rated_dict.items():\n",
    "            self.one_rated[u] = random.sample(self.rated_dict[u], 1)[0]\n",
    "        \n",
    "        # 参数矩阵\n",
    "        self.P = nn.Parameter(torch.empty(self.n_P, self.embed_size))\n",
    "        self.Q = nn.Parameter(torch.empty(self.n_Q, self.embed_size))\n",
    "        nn.init.xavier_normal_(self.P.data)\n",
    "        nn.init.xavier_normal_(self.Q.data)\n",
    "        \n",
    "    \n",
    "    # 生成批训练集，批大小为batch_size\n",
    "    def generate_train_batch(self):\n",
    "        # 记录一批中<u,i,j>的编号\n",
    "        u_batch = []\n",
    "        i_batch = []\n",
    "        j_batch = []\n",
    "    \n",
    "        # 生成batch_size大小的训练集\n",
    "        for b in range(self.batch_size):\n",
    "            # 随机选择u，即user_id\n",
    "            u = random.sample(self.rated_dict.keys(), 1)[0]\n",
    "            u_batch.append(u)\n",
    "            # 随机选择i，即该user已评分过的一个item_id\n",
    "            i = random.sample(self.rated_dict[u], 1)[0]\n",
    "            while i == self.one_rated[u]:  # 防止正好选中了用于测试集的\n",
    "                i = random.sample(self.rated_dict[u], 1)[0]\n",
    "            i_batch.append(i)\n",
    "            # 随机选择j，即该user未评分过的一个item_id\n",
    "            j = random.randint(1, n_Q-1)  # 随机生成item_id\n",
    "            while j in self.rated_dict[u]:  # 防止选到了已评分的\n",
    "                j = random.randint(1, n_Q-1)\n",
    "            j_batch.append(j)\n",
    "        \n",
    "        # 以矩阵方式返回批训练集\n",
    "        return np.asarray(u_batch), np.asarray(i_batch), np.asarray(j_batch)\n",
    "        \n",
    "\n",
    "    # 生成批测试集，每一批对应一个user\n",
    "    def generate_test_batch(self):\n",
    "        for u in self.rated_dict.keys():  \n",
    "            u_test = []\n",
    "            i_test = []\n",
    "            j_test = []\n",
    "            i = self.one_rated[u]  # 随机抽取的一个已评分item\n",
    "            for j in range(1, self.n_P):\n",
    "                if not (j in self.rated_dict[u]):  # 获得该用户所有未评分过的item\n",
    "                    u_test.append(u)\n",
    "                    i_test.append(i)\n",
    "                    j_test.append(j)\n",
    "            yield np.asarray(u_test), np.asarray(i_test), np.asarray(j_test)\n",
    "    \n",
    "    \n",
    "    # 给定u, i, j编号矩阵，计算总误差值\n",
    "    def compute_loss(self, u_array, i_array, j_array):\n",
    "        pu = self.P[u_array, :]\n",
    "        qi = self.Q[i_array, :]\n",
    "        qj = self.Q[j_array, :]\n",
    "        xui = torch.mul(pu, qi).sum(dim=1)\n",
    "        xuj = torch.mul(pu, qj).sum(dim=1)\n",
    "        xuij = xui - xuj\n",
    "        log = F.logsigmoid(xuij).sum()\n",
    "        L2 = self.lmbda * (pu.norm(dim=1).pow(2).sum() + qi.norm(dim=1).pow(2).sum() + qj.norm(dim=1).pow(2).sum())\n",
    "        loss = -log + L2\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    # 训练\n",
    "    def train(self, epochs, samples):\n",
    "        optimizer = optim.SGD([self.P, self.Q], lr=self.lr)\n",
    "        # 多次迭代\n",
    "        for k in range(epochs):\n",
    "            sum_loss = 0\n",
    "            # 每次迭代都有多次采样\n",
    "            for n in range(1, samples):\n",
    "                # 生成批训练集，计算损失值\n",
    "                u_batch, i_batch, j_batch = self.generate_train_batch()\n",
    "                loss = self.compute_loss(u_batch, i_batch, j_batch)\n",
    "                sum_loss += loss\n",
    "                # 优化参数\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            avg_loss = sum_loss/(self.batch_size*n)\n",
    "            # 计算测试误差\n",
    "            test_loss = self.test()\n",
    "            print('epoch %d：avg_loss = %.4f; test_loss = %.4f' % (k+1, avg_loss, test_loss))\n",
    "    \n",
    "    \n",
    "    # 计算测试的平均误差\n",
    "    def test(self):\n",
    "        loss = 0\n",
    "        n = 0\n",
    "        for u_test, i_test, j_test in self.generate_test_batch():\n",
    "            loss += self.compute_loss(u_test, i_test, j_test)\n",
    "            n += len(u_test)\n",
    "        return loss / n\n",
    "    \n",
    "    def see(self):\n",
    "        return self.P, self.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义函数，加载数据\n",
    "\n",
    "def load_data(data_path):\n",
    "    rated_dict = defaultdict(set)\n",
    "    \n",
    "    # 读取文件\n",
    "    inter = pd.read_csv(data_path, delimiter='\\t', engine='python')\n",
    "    df = pd.DataFrame(inter)\n",
    "    \n",
    "    # user, item数目+1\n",
    "    n_P = df['user_id:token'].max() + 1\n",
    "    n_Q = df['item_id:token'].max() + 1\n",
    "    \n",
    "    # 遍历每一行评分数据\n",
    "    for index, row in df.iterrows():\n",
    "        u = row['user_id:token']\n",
    "        i = row['item_id:token']\n",
    "        rated_dict[u].add(i)\n",
    "        \n",
    "    # 返回user数目，item数目，评分字典\n",
    "    return n_P, n_Q, rated_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1：avg_loss = 0.6941; test_loss = 0.6931\n",
      "epoch 2：avg_loss = 0.6679; test_loss = 0.6348\n",
      "epoch 3：avg_loss = 0.5397; test_loss = 0.5975\n",
      "epoch 4：avg_loss = 0.4872; test_loss = 0.5943\n",
      "epoch 5：avg_loss = 0.4766; test_loss = 0.5871\n",
      "epoch 6：avg_loss = 0.4727; test_loss = 0.5810\n",
      "epoch 7：avg_loss = 0.4708; test_loss = 0.5762\n",
      "epoch 8：avg_loss = 0.4697; test_loss = 0.5735\n",
      "epoch 9：avg_loss = 0.4695; test_loss = 0.5722\n",
      "epoch 10：avg_loss = 0.4693; test_loss = 0.5705\n"
     ]
    }
   ],
   "source": [
    "# 加载数据，构造评分字典rated_dict\n",
    "data_path = '../dataset/ml-100k/ml-100k.inter'\n",
    "n_P, n_Q, rated_dict = load_data(data_path)\n",
    "\n",
    "# 构造模型并训练\n",
    "bpr = BPR(n_P, n_Q, rated_dict, lr=0.005, lmbda=0.05, embed_size=10, batch_size=1000)\n",
    "bpr.train(epochs=10, samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
